{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cvičenie 3: Multilayer Perceptron\n",
    "\n",
    "Na dnešnom cvičení budete implementovať doprednú fázu viacvrstvového perceptrónu (multilayer perceptron), teda neurónovej siete s viacerými vrstvami. Fungovanie perceptrónu by vám už malo byť jasné, dnes rozšírime štruktúru o niekoľko neurónov, ktoré zoskupujeme do troch vrstiev (vstupná, skrytá a výstupná). Do neurónov takisto pridáme aktivačné funkcie ReLU a sigmoid.\n",
    "\n",
    "Pred tým než sa spustíte do práce, zopakujte si teoretické znalosti o neurónových sieťach, najmä čo sa týka jednotlivých výpočtov ktoré sa vykonajú v rámci neurónov. Pri diskusii vám môže pomôcť architektúra multilayer perceptrona:\n",
    "\n",
    "![Štruktúra neurónovej siete](sources/lab03/3.1-mlp-structure.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prvý pohľad na kód"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stiahnite si [kostru riešenia](sources/lab03/lab3.zip), ktorá obsahuje Python skript s prázdnymi triedami pre implementáciu neurónovej siete. Trieda `Layer` popisuje všeobecné rozhranie jednej vrstvy v neurónovej sieti, ktorá má:\n",
    "* doprednú fázu (`forward`) - výpočet výstupu na základe vstupu, teda predikcia\n",
    "* trénovaciu fázu (`backward`) - trénovanie siete, aktualizácia váh.\n",
    "\n",
    "Vašou úlohou je implementovať vrstvy ` ReLU`, `Dense` a `Sigmoid` rovnako ako triedu `MLP` pre samotnú neurónovú sieť.\n",
    "\n",
    "Skript ďalej obsahuje niekoľko testových vstupov, na ktorom neskôr otestujeme vaše riešenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na začiatku zavoláme potrebnú knižnicu `numpy` pre podporu výpočtov s maticami rôznych rozmerov. Následne nastavíme generovanie náhodných čísel, čo neskôr využijeme pre inicializáciu váh, aby naše pokusy boli opakovateľné:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(42)  # set random number generator for reproducability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trieda `Layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvá trieda definovaná v skripte je tzv. dummy trieda, ktorá je veľmi podobná abstraktným triedam a reprezentuje všeobecnú funkcionalitu vrstvy neurónovej siete. Túto triedu reálne nikdy nevyužijeme, budú však od nej dediť všetky ostatné implementované triedy. Práve preto konštruktor tejto triedy je prázdny, implementovaný je iba prechodná časť, teda funkcia `forward`, ktorá vráti iba hodnoty na vstupe. Funkciu `backward` nebudeme implementovať, ak sa rozhodnite vaše zadania vypracovať na základe tohto riešenia, môžete tu pridať všeobecný spôsob trénovania vrstiev v neurónovej sieti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    This is just a dummy class that is supposed to represent the general\n",
    "    functionality of a neural network layer. Each layer can do two things:\n",
    "     - forward pass - prediction\n",
    "     - backward pass - training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # a dummy layer returns the input\n",
    "        return inp\n",
    "\n",
    "    def backward(self, inp, grad_outp):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trieda `ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V ďalšom kroku implementujeme triedu ReLU, ktorá reprezentuje aktivačnú funkciu [ReLU](https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7). Naše riešenie teda rozdeľuje výpočet váženej sumy od výpočtu výstupu aktivačnej funkcie - akokeby sme rozdelili jednu vrstvu na dve vrstvy: jedna pre výpočet sumy, jedna pre aktivačnú funkciu. Pri implementácii neurónovej siete tento rozdiel v reprezentácii skryjeme ako implementačný detail.\n",
    "\n",
    "Aktivačná funkcia je veľmi jednoduchá funkcia, ktorá sa používa najmä v hlbokom učení, ale vzhľadom na jej jednoduchosť ju použijeme aj v tomto kroku, aby sme vedeli jednoduchšie otestovať naše riešenie. Vzorec ReLU je nasledovný:\n",
    "\n",
    "$ReLU(x) = \\left\\{\\begin{matrix}\n",
    "x & ak x > 0\\\\ \n",
    "0 & naopak\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "Urobte analýzu triedy, navrhnite a implementujte riešenie - konštruktor a funkciu `forward`, pre ktorú vstupom bude výsledok z váženej sumy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return 0.0\n",
    "\n",
    "    def backward(self, inp, grad_outp):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trieda `Dense`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V tomto kroku implementujete triedu pre plne prepojenú vrstvu (po anglicky *fully-connected layer* alebo *dense layer*). Vstupom do tejto vrstvy sú vstupné dáta alebo výstupy predošlej (aktivačnej) vrstvy. Urobte analýzu triedy a navrhnite riešenie pre konštruktor a funkciu `forward`.\n",
    "\n",
    "Konštruktor má nasledujúce parametre:\n",
    "* `inp_units` - počet vstupov do každého neurónu, teda počet neurónov v predošlej vrstve\n",
    "* `outp_units` - počet výstupu, teda počet neurónov v danej vrstve\n",
    "* `learning_rate` - hodnota učiaceho parametra, ktorý hrá rolu pri trénovanie neurónky\n",
    "\n",
    "Funkcia `forward` má jediný parameter:\n",
    "* `inp` - vektor vstupných hodnôt do každého jedného neurónu v danej vrstve\n",
    "\n",
    "Triedu môžete rozšíriť o rôzne ďalšie potrebné metódy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, inp_units, outp_units, learning_rate=0.1):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return 0.0\n",
    "\n",
    "    def backward(self, inp, grad_outp):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trieda `MLP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ak máme implementovanú vrstvu pre výpočet váženej sumy a pre aktivačnú funkciu, môžeme z nich vytvoriť neurónovú sieť, teda viacvrstvový perceptrón. Trieda `MLP` je určený pre tento účel a definuje nasledujúce funkcie:\n",
    "\n",
    "* `__init__` - konštruktor triedy, bez parametrov\n",
    "* `add_layer` - pridá vrstvu do neurónovej siete; vašou úlohou je skryť pred používateľom vášho riešenia implementačné detaily (vrstva je reálne rozdelená do dvoch vrstiev), práve preto použijeme rozhranie, ktoré je veľmi bežné pre rôzne knižnice na vytvorenie neurónových sietí:\n",
    "  * `neuron_count` - počet neurónov v danej vrstve\n",
    "  * `inp_shape` - tvar vstupu pre danú vrstvu; defaultne je `None`, používateľ ho potrebuje zadefinovať iba pre prvú vrstvu, pre ďalšie vrstvy sa určí na základe predošlej vrstvy\n",
    "  * `activation` - aktivačná funkcia použitá v danej vrstve; defaultne má hodnotu ReLU, môžete už pridať podporu pre sigmoidálnu funkciu (aj keď zatiaľ nie je implementovaná)\n",
    "* `forward` - funkcia vypočíta výsledok doprednej fázy neurónovej siete pre vstup `X`; pre zjednodušenie ladenia programu vám odporúčame, aby funkcia nevrátila iba celkový výsledok (výstup z výstupnej vrstvy) ale výstup pre každú vrstvu (medzivýsledky postupne pridávajte do zoznamu `activations`)\n",
    "* `predict` - funkcia vráti predikciu neurónovej siete pre vstup `X`; viacvrstvový perceptrón sa používa pre klasifikáciu, predikcia má byť index najvyššej hodnoty vo výstupe z výstupnej vrstvy\n",
    "* `fit` - funkcia slúži na trénovanie neurónovej siete pre vstup `X` a očakávaný výstup `y`; zatiaľ ju nebudeme implementovať\n",
    "\n",
    "Urobte analýzu triedy a následne ju implementujte na základe navrhnutého riešenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_layer(self, neuron_count, inp_shape=None, activation='sigmoid'):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        activations = []\n",
    "\n",
    "        return activations\n",
    "\n",
    "    def predict(self, X):\n",
    "        return 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testovanie riešenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ak ste úspešne implementovali vrstvy a sieť, môžete vaše riešenie vyskúšať na reálnom príklade. V metóde `main` máte definované dve vstupy s dĺžkou tri (pole `test`).\n",
    "\n",
    "Do premennej `network` pridajte vrstvy a otestujte korektnosť riešenia zavolaním funkcie `predict`. Alternatívne, môžete vypísať aj výstup z funkcie `forward`, aby ste vedeli skontrolovať aj medzivýsledky. Odporúčame vypísať aj hodnoty váh v jednotlivých vrstvách, aby ste vedeli porovnať výstup neurónovej siete s očakávaným výstupom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [[300, 400, 500], [2, 0, 1]]\n",
    "test = np.array(test)\n",
    "\n",
    "network = MLP()\n",
    "\n",
    "# TODO: add layers to the network\n",
    "\n",
    "print(network.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vrstva `Sigmoid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ak vaše riešenie funguje správne, môžete ho rozšíriť triedou a teda aktivačnou funkciou `Sigmoid`. Implementácia bude veľmi podobná vrstve `ReLU`, iba použijete iný spôsob výpočtu výsledku:\n",
    "\n",
    "$sigmoid(x) = \\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return 0.0\n",
    "\n",
    "    def backward(self, inp, grad_outp):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následne môžete zadefinovať nový model so sigmoidálnou aktivačnou funkciou a otestovať jeho fungovanie. Sústreďte sa na rozdiely medzi dvomi aktivačnými funkciami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [[300, 400, 500], [2, 0, 1]]\n",
    "test = np.array(test)\n",
    "\n",
    "network = MLP()\n",
    "\n",
    "# TODO: add layers to the network\n",
    "\n",
    "print(network.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ukážkové riešenie cvičenia nájdete na [tejto adrese](sources/lab03/lab03-mlp-solution.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
